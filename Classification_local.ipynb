{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejecución de manera local\n",
    "\n",
    "En este cuaderno de Jupyter se hará la implementación de la clasificación de personajes de los simpsons de manera local. Se utiliza una GPU NVIDIA GeForce GTX 1650 para efectuar todo el proceso y se corre en un entorno de Anaconda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LCqFQJGDpj5m"
   },
   "source": [
    "## Inclusión de bibliotecas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se mencionó, se utilza un entorno de Anaconda para trabajar y es necesario que este entrono se de una versión python 3.8 o superior, además de incluir los siguientes paquetes:\n",
    "\n",
    "```\n",
    "conda install numpy\n",
    "conda install pip\n",
    "conda install -c conda-forge opencv\n",
    "conda install -c conda-forge matplotlib\n",
    "\n",
    "conda install -c conda-forge pickle5\n",
    "conda install -c anaconda h5py\n",
    "conda install scikit-learn\n",
    "conda install -c conda-forge glob2\n",
    "conda install -c conda-forge keras\n",
    "conda install -c anaconda pandas\n",
    "conda install -c anaconda scikit-image\n",
    "conda install -c anaconda pillow\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wVzItQDrkNK7",
    "outputId": "170067ea-4895-4f53-b3db-070ec407879d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Se importan las bibliotecas. En caso de querer hacer este proceso directamente\n",
    "#en un ordenador se deben instalar las bilbiotecas que se indican a continuacion:\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import h5py\n",
    "import sklearn\n",
    "\n",
    "import glob\n",
    "import keras\n",
    "import time\n",
    "import imp\n",
    "import os\n",
    "import tensorflow as tf \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#Estas bibliotecas no son necesarias en su totalidad, solo se requieren ciertas\n",
    "#funciones\n",
    "from random import shuffle\n",
    "from skimage import io\n",
    "from collections import Counter\n",
    "from PIL import Image, ImageFont, ImageDraw, ImageEnhance\n",
    "\n",
    "#Importe de funciones especificas de bibliotecas ya importadas\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "#lineas requeridas solo en jupyter notbook\n",
    "#%matplotlib inline\n",
    "#%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B4U_cyn-ygjP"
   },
   "source": [
    "## Lectura y preprocesado de datos\n",
    "\n",
    "Como se esta haciendo el proceso de entrenamiento de manera local, se deben descargar las imágenes y colocar en el mismo directorio que el presente notbook. Viendose el entorno de trabajo de manera similar a:\n",
    "\n",
    "\n",
    "```\n",
    "characters/\n",
    "    |-> abraham_grampa_simpson/\n",
    "    |-> agnes_skinner/\n",
    "    |-> apu_nahasapeemapetilon/\n",
    "    \n",
    "Images_Simpsons/\n",
    "    |-> Extra_Images/\n",
    "    |-> annotation.txt\n",
    "\n",
    "Classification_local.ipynb\n",
    "\n",
    "```\n",
    "\n",
    "Donde dentro del directorio *characters* se encuentran multiples directorios con el nombre de un personaje de los simpsons y dentro de cada uno estan las imágenes de los personajes según se especifica en el nombre del directorio. Por otra parte el directorio *Images_Simpsons* contiene las imágenes extra, que se usan para hacer pruebas de desempeño de la red, y el archivo *annotation.txt* que incluye las coordenadas del lugar en la imagen donde esta cada personaje. Esto último no se usa en este proyecto, ya que solo estamos haciendo clasificación pero se utilizará en en el futuro cuando se realice la detección.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "rs4yleHOvJhj",
    "outputId": "79a1139e-851d-4e57-ccad-526bc8a1ab48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (14426, 64, 64, 3) (14426, 19)\n",
      "Test (2546, 64, 64, 3) (2546, 19)\n",
      "krusty_the_clown : 1016 train pictures & 160 test pictures\n",
      "bart_simpson : 1008 train pictures & 168 test pictures\n",
      "charles_montgomery_burns : 1001 train pictures & 175 test pictures\n",
      "ned_flanders : 1001 train pictures & 175 test pictures\n",
      "lisa_simpson : 1000 train pictures & 176 test pictures\n",
      "moe_szyslak : 998 train pictures & 178 test pictures\n",
      "homer_simpson : 995 train pictures & 181 test pictures\n",
      "principal_skinner : 983 train pictures & 193 test pictures\n",
      "marge_simpson : 981 train pictures & 195 test pictures\n",
      "milhouse_van_houten : 921 train pictures & 158 test pictures\n",
      "chief_wiggum : 861 train pictures & 125 test pictures\n",
      "abraham_grampa_simpson : 752 train pictures & 161 test pictures\n",
      "sideshow_bob : 747 train pictures & 130 test pictures\n",
      "apu_nahasapeemapetilon : 536 train pictures & 87 test pictures\n",
      "kent_brockman : 426 train pictures & 72 test pictures\n",
      "comic_book_guy : 400 train pictures & 69 test pictures\n",
      "edna_krabappel : 394 train pictures & 63 test pictures\n",
      "nelson_muntz : 300 train pictures & 58 test pictures\n",
      "maggie_simpson : 106 train pictures & 22 test pictures\n"
     ]
    }
   ],
   "source": [
    "#Se inicia definiendo el diccionario map_characters, este posee originalmente 18\n",
    "#personajes, si se agrega otro más se debe agregar al diccionario y colocarsele \n",
    "#el número consecutivo que corresponda\n",
    "map_characters = {0: 'abraham_grampa_simpson', \n",
    "                  1: 'apu_nahasapeemapetilon', \n",
    "                  2: 'bart_simpson',\n",
    "                  3: 'charles_montgomery_burns', \n",
    "                  4: 'chief_wiggum', \n",
    "                  5: 'comic_book_guy', \n",
    "                  6: 'edna_krabappel', \n",
    "                  7: 'homer_simpson', \n",
    "                  8: 'kent_brockman', \n",
    "                  9: 'krusty_the_clown', \n",
    "                  10: 'lisa_simpson', \n",
    "                  11: 'marge_simpson', \n",
    "                  12: 'milhouse_van_houten', \n",
    "                  13: 'moe_szyslak', \n",
    "                  14: 'ned_flanders', \n",
    "                  15: 'nelson_muntz', \n",
    "                  16: 'principal_skinner', \n",
    "                  17: 'sideshow_bob',\n",
    "                  18: 'maggie_simpson'}\n",
    "                  \n",
    "#Se define el numero de clases con la extensión del diccionario\n",
    "num_classes = len(map_characters)\n",
    "\n",
    "#Número máximo de imagenes que se usaran por personaje para entrenar\n",
    "pictures_per_class = 1000\n",
    "\n",
    "def load_pictures(test_size, pic_size,BGR):\n",
    "    \"\"\"\n",
    "    Load pictures from folders for characters from the map_characters dict and create a numpy dataset and \n",
    "    a numpy labels set. Pictures are re-sized into picture_size square.\n",
    "    :param BGR: boolean to use true color for the picture (RGB instead of BGR for plt)\n",
    "    :return: dataset, labels set\n",
    "    \"\"\"\n",
    "    pics = []    #Se crea la lista de imagenes de salida\n",
    "    labels = []  #Se crea la lista de etiquetas de salida\n",
    "\n",
    "    #k es el numero de la variable en el diccionario\n",
    "    #char es el nombre de la variable en el diccionario\n",
    "    # El if lo que hace es que recorra cada una de las variables del diccionario\n",
    "    for k, char in map_characters.items(): \n",
    "\n",
    "        #Esta linea deivuelve la lista de rutas de las imagenes de cada personaje del diccionario\n",
    "        # Ej: para char = 'abraham_grampa_simpson' regresa todas las rutas de imagen de la carpeta\n",
    "        # abraham_grampa_simpson que a su vez esta en la carpeta characters.\n",
    "        #Es solo una forma elegante y rapida de optener todas las rutas \n",
    "        pictures = [k for k in glob.glob('./characters/%s/*' % char)]\n",
    "\n",
    "        #Se establece la cantidad de imagenes que se van a usar en cada clase\n",
    "        #Como maximo se usan 1176 imagenes, estas son tanto para train como para test\n",
    "        #Si el personaje en particular tiene menos de 1176 imagenes se usara la extension del personaje en cuestion\n",
    "        nb_pic = round(pictures_per_class/(1-test_size)) if round(pictures_per_class/(1-test_size))<len(pictures) else len(pictures)\n",
    "\n",
    "        #Se usa la funcion random para ordenar de manera aleatoria las imagenes de cada personaje\n",
    "        #Cabe detacar que pic es una ruta de acceso aleatoria de la lista de rutas de acceso en pictures\n",
    "        for pic in np.random.choice(pictures, nb_pic):\n",
    "\n",
    "            #Se lee la imagen de la ruta \"pic\"\n",
    "            a = cv2.imread(pic)\n",
    "\n",
    "            #Si se desea se usa RGB se hace la transformacion de BGR, que es la lectura original\n",
    "            #Por defecto este cambio no se hace a menos que se especifique\n",
    "            if BGR:\n",
    "                a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            #Se hace un resize de las imagenes a pic_size x pic_size. Por defecoto\n",
    "            #este es 64x64. Esto concuerda con los pixeles de entrada de la red neuronal\n",
    "            a = cv2.resize(a, (pic_size,pic_size))\n",
    "\n",
    "            #Se agrega la imagen leida, convertida y escalada a la lista pics\n",
    "            pics.append(a)\n",
    "            #Se agrega la etiqueta numérica de la lista de etiquetas, esta etiqueta numerica \n",
    "            #concuerda con el número en el diccionario map_characters\n",
    "            labels.append(k)\n",
    "\n",
    "    #Se devuelve las listas pero antes se transforman a un formato de array con numpy\n",
    "    return np.array(pics), np.array(labels) \n",
    "\n",
    "def get_dataset(save=False, load=False, BGR=False, test_size=0.15, pic_size=64):\n",
    "    \"\"\"\n",
    "    Create the actual dataset split into train and test, pictures content is as float32 and\n",
    "    normalized (/255.). The dataset could be saved or loaded from h5 files.\n",
    "    :param save: saving or not the created dataset\n",
    "    :param load: loading or not the dataset\n",
    "    :param BGR: boolean to use true color for the picture (RGB instead of BGR for plt)\n",
    "    :return: X_train, X_test, y_train, y_test (numpy arrays)\n",
    "    \"\"\"\n",
    "    #Si ya se tienen listos de antemano se cargan directamente de memoria, por \n",
    "    #defecto esta opcion esta desactivada\n",
    "    if load:\n",
    "        #Se lee directamente el archivo 'dataset.h5', aqui estan tanto el set de \n",
    "        #entrenamiento como el de test \n",
    "        h5f = h5py.File('dataset.h5','r')\n",
    "        \n",
    "        #Se divide entre set de train y set de test, esto gracias a la etiqueta\n",
    "        #que el archivo .h5 trae, similar a un formato .json\n",
    "        X_train = h5f['X_train'][:]\n",
    "        X_test = h5f['X_test'][:]\n",
    "        h5f.close()\n",
    "\n",
    "        #Se hace un proceso igual pero para los labels\n",
    "        h5f = h5py.File('labels.h5','r')\n",
    "        y_train = h5f['y_train'][:]\n",
    "        y_test = h5f['y_test'][:]\n",
    "        h5f.close()    \n",
    "    \n",
    "    #En caso de que no esten en memoria los sets de entrenamiento y test se \n",
    "    #realiza todo el procesamiento desde cero\n",
    "    else:\n",
    "        #Primero se llama a la funcion load_pictures, por defecto se deja estas en \n",
    "        #blanco y negro\n",
    "        #En esta funcion tambien se extraen los labels del archivo txt anotations\n",
    "        X, y = load_pictures(test_size, pic_size, BGR)\n",
    "\n",
    "        #Luego se pasa los labels a un formato numerico y en listas separadas,\n",
    "        #por ejemplo si el label es 2 to_categorical lo pasa a una lista [0 0 1 ... 0]\n",
    "        #El tamaño de la lista depende de cuantas clases se tenga, en este ejemplo son 18\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "\n",
    "        #Posteriormente se divide todos los datos en set de train y test, el tamaño del\n",
    "        #set de test esta dado por la variable test_size, por defecto es 15%\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "        \n",
    "        #Se guarda los sets creados en archivos con formato .h5, tanto los labels como\n",
    "        #las imagenes\n",
    "        if save:\n",
    "            h5f = h5py.File('dataset.h5', 'w')\n",
    "            h5f.create_dataset('X_train', data=X_train)\n",
    "            h5f.create_dataset('X_test', data=X_test)\n",
    "            h5f.close()\n",
    "\n",
    "            h5f = h5py.File('labels.h5', 'w')\n",
    "            h5f.create_dataset('y_train', data=y_train)\n",
    "            h5f.create_dataset('y_test', data=y_test)\n",
    "            h5f.close()\n",
    "\n",
    "    #Se normaliza las imagenes para que los valores de cada banda esten en punto flotante\n",
    "    #y además se encuentren entre 0 y 1. Esto ayuda a la velocidad de entrenamiento           \n",
    "    X_train = X_train.astype('float32') / 255.\n",
    "    X_test = X_test.astype('float32') / 255.\n",
    "    \n",
    "    #Se imprime las formas de cada tensor. Si se mantienen todas las variables \n",
    "    #por defecto estas deben ser (x,64,64,3) y (x,w), donde x es el numero de imagenes\n",
    "    #y w es la cantidad de clases en el diccionario\n",
    "    print(\"Train\", X_train.shape, y_train.shape)\n",
    "    print(\"Test\", X_test.shape, y_test.shape)\n",
    "\n",
    "    #Imprime la cantidad de imagenes por personaje y la cantidad de imagenes en \n",
    "    #que se pusieron en el set de train y en el set de test\n",
    "    if not load:\n",
    "        #Se crea un diccionario donde cada variable esta asociada a una lista que contiene la extension del set\n",
    "        #de train y test para cada personaje\n",
    "        dist = {k:tuple(d[k] for d in [dict(Counter(np.where(y_train==1)[1])), dict(Counter(np.where(y_test==1)[1]))]) \n",
    "                for k in range(num_classes)}\n",
    "\n",
    "        #Se imprime en orden decendente\n",
    "        print('\\n'.join([\"%s : %d train pictures & %d test pictures\" % (map_characters[k], v[0], v[1]) \n",
    "            for k,v in sorted(dist.items(), key=lambda x:x[1][0], reverse=True)]))\n",
    "    \n",
    "    #Se devuelve los set de datos divididas en train y test. Esto tanto para las \n",
    "    #imagenes como para los labels.\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "#Uso de funciones de lectura para dividir el set de imagnes en test y train\n",
    "X_train, X_test, y_train, y_test = get_dataset(save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KN0eB4Wpyre4"
   },
   "source": [
    "## Creacion de redes neuronales (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LwDtYNixycBj"
   },
   "outputs": [],
   "source": [
    "#Se tiene una red neuronal convolucional de cuatro capas convolucionales\n",
    "def create_model_four_conv(input_shape):\n",
    "    \"\"\"\n",
    "    CNN Keras model with 4 convolutions.\n",
    "    :param input_shape: input shape, generally X_train.shape[1:]\n",
    "    :return: Keras model, RMS prop optimizer\n",
    "    \"\"\"\n",
    "\n",
    "    #Se crea primeramente un modelo \"Sequential\", este es el tipo de red neuronal\n",
    "    #existen otros tipos como las recursivas y las recurrentes.\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Se usa mucho las capas Conv2D, por lo que se explicara solo una vez. Estas \n",
    "    #tienen el formato por defecto:\n",
    "    \n",
    "    #tf.keras.layers.Conv2D(\n",
    "    #    filters, kernel_size, strides=(1, 1), padding='valid', data_format=None,\n",
    "    #    dilation_rate=(1, 1), activation=None, use_bias=True,\n",
    "    #    kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
    "    #    kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None,\n",
    "    #    kernel_constraint=None, bias_constraint=None, **kwargs)\n",
    "    #\n",
    "    #Donde:\n",
    "    #\"filters\" se refiere a la cantidad de filtros que se tienen en esa capa, \n",
    "    #por ejemplo en la primera capa se tiene 32 filtros.\n",
    "    #Los filtros son los que cambuan durante el entrenamiento.\n",
    "    \n",
    "    #\"strides\" es siempre una tupla. Se refiere a las dimenciones dadas para \n",
    "    #cada filtro, por defecto esta variable tiene como valor la tupla (1,1). \n",
    "    #Por ejemplo, en la primera capa se usa una dimensión para los filtros (3,3)\n",
    "    \n",
    "    #\"padding\" es una bandera que puede ser \"valid\" (opcion por defecto) \n",
    "    #o \"same\" (case-insensitive). La opción valid tiene la posibilidad de perder\n",
    "    #informacion de entrada en especial de las esquinas. Por otra parte same\n",
    "    #aplica rellenos en las esquinas de modo que se usen todos los pixeles de entrada\n",
    "\n",
    "    #\"input_shape\" se usa solo en la capa (layer) de entrada\n",
    "\n",
    "    #¿Que recibe de entrada y que obtiene de salida estas capas?\n",
    "    #La entrada debe ser un tensor de 4D con el formato:\n",
    "    #   (batch_size, rows, cols, channels), si data_format='channels_last' esta \n",
    "    #     es la opcion por defecto de \"data_format\"\n",
    "    #\n",
    "    #   (batch_size, channels, rows, cols), si data_format='channels_first'\n",
    "    #\n",
    "    #La salida es otro tensor de 4D con el formato:\n",
    "    #   (batch_size, new_rows, new_cols, filters), si data_format='channels_last' \n",
    "    #     esta es la opcion por defecto de \"data_format\"\n",
    "    #\n",
    "    #   (batch_size, filters, new_rows, new_cols), si data_format='channels_first' \n",
    "    #\n",
    "    #rows and cols pueden variar dependiendo de la bandera \"padding\", con \"same\"\n",
    "    #se tendrían la misma candtidad de rows y cols de salida que de entrada.\n",
    "\n",
    "    #Primera capa convolucional\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
    "\n",
    "    #Se agrega una funcion de activación, se puede agregar directamente en la capa\n",
    "    #convolucional pero esto haría que se pusiera la activación en la entrada, \n",
    "    #se decide poner la activación en la salida.\n",
    "    #La función de activación que se usa es la \"relu\" pero existen otras funciones\n",
    "    #de activación, estas se pueden encontrar aqui:\n",
    "    #https://www.tensorflow.org/api_docs/python/tf/keras/activations \n",
    "    #Relu hace que los valores con un valor menor a 1 se vuelvan 0\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #Como resultado de la primera capa convolucional se tiene 32 capas de profundidad\n",
    "    #y cada una de estas capas poseen las mismas dimensiones que la imagen de entrada\n",
    "    #en caso de mantener la configuracion por defecto se tiene 64x64x32, se puede \n",
    "    #ver como un cubo con tres dimensiones: largo, ancho y profundidad \n",
    "\n",
    "    #Segunda capa convolucional, con 32 filtros\n",
    "    #Esta segunda capa sigue siendo convolucional pero notese que no posee el \n",
    "    #padding, como resultado se pierde las últimas filas y columnas (los bordes)\n",
    "    #por lo que para este caso el cubo seria de dimenciones 62x62x32, ya que \n",
    "    #aún se tienen los 32 filtros. La función de activación sigue siendo \"relu\".\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    #Una capa Maxpolling2D reduce la cantidad de col y rows, en este caso\n",
    "    #se reduce de una matriz 2x2 a un único escalar, como consecuencia se tiene\n",
    "    #como resultado un cubo 31x31x32.\n",
    "    #Los layers de pool lo que hacen es reducir la cantidad de filas y columnas\n",
    "    #de entrada, esto puede hacerse por promedio, minimo, maximo o una función\n",
    "    #en este caso MaxPooling lo que hace es usar el valor máximo de la matriz que\n",
    "    #está viendo. (de la matriz 2x2 agarra el valor máximo y ese es el resultado)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    #Las capas dropout se usa para evitar el overfiting, estas solo se activan\n",
    "    #durante el entrenamiento, y su función es hacer cero entradas de manera aleatoria\n",
    "    #con un taza de ocurrencia seleccionada por el usuario (en este caso es de 25%)\n",
    "    #las que no son colocadas en 0 se multiplican por 1/(1-rate)\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    #Tercera capa convolucional, con 64 filtros\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    #Cuarta capa convolucional, con 64 filtros\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    #La capa \"flatten\" lo que hace es pasar de las capas convolucionales y 3D a \n",
    "    #capas en una dimensión. Un único vector horizontal.\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #Se reduce la cantidad de neuronas, en este casi particular se pasa de la cantidad\n",
    "    #dada por Flatten y se pasa a 512 nueronas, se recomienda siempre usar 2^n valores\n",
    "    #Esta capa se le conoce como fully connected layer\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    #Finalmente se reduce a la cantidad de neuronas equivalentes a la cantidad de clases\n",
    "    #que se desean, en nuestro caso, la cantidad de personajes que estamos clasificando\n",
    "    model.add(Dense(num_classes))\n",
    "    #\"softmax\" convierte el valor en probabilidad de 0 a 1.\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    #Se define la funcion de optimización\n",
    "    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "    return model, opt\n",
    "\n",
    "\n",
    "#Igual que el caso anterior pero se tiene una red de 6 capas convolucionales\n",
    "def create_model_six_conv(input_shape):\n",
    "    \"\"\"\n",
    "    CNN Keras model with 6 convolutions.\n",
    "    :param input_shape: input shape, generally X_train.shape[1:]\n",
    "    :return: Keras model, RMS prop optimizer\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same')) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    opt = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    return model, opt\n",
    "\n",
    "\n",
    "#Igual que el caso anterior pero se tiene una red de 8 capas convolucionales\n",
    "def create_model_eight_conv(input_shape):\n",
    "    \"\"\"\n",
    "    CNN Keras model with 8 convolutions.\n",
    "    :param input_shape: input shape, generally X_train.shape[1:]\n",
    "    :return: Keras model, RMS prop optimizer\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same')) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same')) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(512, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2048))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "    #opt = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    return model, opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aABJClKBy2Zv"
   },
   "source": [
    "## Entrenamiento y Puebas con la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ZoCIjJAC0CV"
   },
   "outputs": [],
   "source": [
    "def load_model_from_checkpoint(weights_path, six_conv=False, pic_size=64):\n",
    "    input_shape=(pic_size,pic_size,3)\n",
    "    if six_conv:\n",
    "        model, opt = create_model_six_conv(input_shape)\n",
    "    else:\n",
    "        model, opt = create_model_four_conv(input_shape)\n",
    "    model.load_weights(weights_path)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#Función para modificar el learning rate\n",
    "def lr_schedule(epoch):\n",
    "    lr = 0.01\n",
    "    return lr*(0.7**int(epoch/10))\n",
    "\n",
    "#Función de entrenamiento\n",
    "def training(model, X_train, X_test, y_train, y_test, data_augmentation=True, epochs=400, batch_size=32):\n",
    "    \"\"\"\n",
    "    Training.\n",
    "    :param model: Keras sequential model\n",
    "    :param data_augmentation: boolean for data_augmentation (default:True)\n",
    "    :param callback: boolean for saving model checkpoints and get the best saved model\n",
    "    :param six_conv: boolean for using the 6 convs model (default:False, so 4 convs)\n",
    "    :return: model and epochs history (acc, loss, val_acc, val_loss for every epoch)\n",
    "    \"\"\"\n",
    "    if data_augmentation:\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "        \n",
    "        # Compute quantities required for feature-wise normalization\n",
    "        # (std, mean, and principal components if ZCA whitening is applied).\n",
    "        datagen.fit(X_train)\n",
    "        \n",
    "        #Las funciones callback son funciones que se ejecutan periodicamente si \n",
    "        #se cumplen ciertas condiciones, en este caso se desea hacer un checkpoint\n",
    "        #este tiene el siguiente formato:\n",
    "        # tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', \n",
    "        #                                     verbose=0, save_best_only=False,\n",
    "        #                                     save_weights_only=False, mode='auto',\n",
    "        #                                     save_freq='epoch', **kwargs)\n",
    "\n",
    "        #Se define el nombre que tendran los pesos guardados automaticamente\n",
    "        filepath='best_weights.hdf5'\n",
    "\n",
    "        #En algunas versiones de tensorflow val_accuracy se cambia por val_acc,\n",
    "        #esta es la variable que define si se va a guardar o no los pesos, en caso\n",
    "        #de que el acc suba o no. Este acc es del set de validación.\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=0, save_best_only=True, save_weights_only=True, mode='max')\n",
    "        \n",
    "        #Además del checkpoint se agrega otra funcion en callback para que se vaya\n",
    "        #ejecutando el entrenamiento, esta es la funcion lr_schedule, que va\n",
    "        #modificando el learning rate.\n",
    "        #\n",
    "        #\"LearningRateScheduler\" es una función de keras para modificar el learning rate\n",
    "        #esta función debe recivir como entrada otra función, a la que se le ingresa la\n",
    "        #epoca en la que se encuentra el entrenamiento. La documentación esta en:\n",
    "        #https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler?hl=en\n",
    "\n",
    "        callbacks_list = [LearningRateScheduler(lr_schedule) ,checkpoint]\n",
    "        \n",
    "        #fit(x=None,       y=None,  batch_size=None, epochs=1,    verbose=1,    callbacks=None,\n",
    "        #   validation_split=0.0 , validation_data=None      , shuffle=True, class_weight=None,\n",
    "        #   sample_weight=None   , initial_epoch=0           , steps_per_epoch=None,\n",
    "        #   validation_steps=None, validation_batch_size=None, validation_freq=1,\n",
    "        #   max_queue_size=10    , workers=1                 , use_multiprocessing=False)\n",
    "\n",
    "        #Inicio de entrenamiento\n",
    "        history = model.fit(datagen.flow(X_train, y_train,\n",
    "                            batch_size=batch_size),\n",
    "                            steps_per_epoch=X_train.shape[0] / batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(X_test, y_test),\n",
    "                            callbacks= callbacks_list,\n",
    "                            shuffle=True)\n",
    "    else:\n",
    "        #Difinicion de los callbacks, son los mismos que se usan arriba\n",
    "        filepath='best_weights.hdf5'\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=0, save_best_only=True, save_weights_only=True, mode='max')\n",
    "        callbacks_list = [LearningRateScheduler(lr_schedule) ,checkpoint]\n",
    "        \n",
    "        #Inicio de entrenamiento\n",
    "        history = model.fit(X_train, y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(X_test, y_test),\n",
    "                            callbacks= callbacks_list,\n",
    "                            shuffle=True)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "88C7b-mIlSq2",
    "outputId": "0ab5f879-6813-4fe9-bb3c-4559a867ea7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "451/450 [==============================] - 20s 45ms/step - loss: 2.6597 - accuracy: 0.1684 - val_loss: 2.4034 - val_accuracy: 0.2537\n",
      "Epoch 2/100\n",
      "451/450 [==============================] - 15s 33ms/step - loss: 2.2295 - accuracy: 0.3138 - val_loss: 1.7726 - val_accuracy: 0.4796\n",
      "Epoch 3/100\n",
      "451/450 [==============================] - 15s 33ms/step - loss: 1.7405 - accuracy: 0.4650 - val_loss: 1.3647 - val_accuracy: 0.5844\n",
      "Epoch 4/100\n",
      "451/450 [==============================] - 15s 33ms/step - loss: 1.3877 - accuracy: 0.5803 - val_loss: 1.1137 - val_accuracy: 0.6748\n",
      "Epoch 5/100\n",
      "451/450 [==============================] - 15s 33ms/step - loss: 1.1193 - accuracy: 0.6617 - val_loss: 0.8316 - val_accuracy: 0.7463\n",
      "Epoch 6/100\n",
      "451/450 [==============================] - 15s 34ms/step - loss: 0.9278 - accuracy: 0.7224 - val_loss: 0.6541 - val_accuracy: 0.7946\n",
      "Epoch 7/100\n",
      "451/450 [==============================] - 15s 33ms/step - loss: 0.7601 - accuracy: 0.7690 - val_loss: 0.5613 - val_accuracy: 0.8291\n",
      "Epoch 8/100\n",
      "451/450 [==============================] - 15s 34ms/step - loss: 0.6616 - accuracy: 0.7993 - val_loss: 0.5008 - val_accuracy: 0.8559\n",
      "Epoch 9/100\n",
      "451/450 [==============================] - 15s 34ms/step - loss: 0.5910 - accuracy: 0.8228 - val_loss: 0.4649 - val_accuracy: 0.8657\n",
      "Epoch 10/100\n",
      "451/450 [==============================] - 15s 34ms/step - loss: 0.5108 - accuracy: 0.8472 - val_loss: 0.5048 - val_accuracy: 0.8547\n",
      "Epoch 11/100\n",
      "451/450 [==============================] - 16s 35ms/step - loss: 0.4855 - accuracy: 0.8551 - val_loss: 0.4380 - val_accuracy: 0.8826\n",
      "Epoch 12/100\n",
      "451/450 [==============================] - 16s 34ms/step - loss: 0.4333 - accuracy: 0.8693 - val_loss: 0.3603 - val_accuracy: 0.9057\n",
      "Epoch 13/100\n",
      "451/450 [==============================] - 15s 34ms/step - loss: 0.4154 - accuracy: 0.8783 - val_loss: 0.3223 - val_accuracy: 0.9089\n",
      "Epoch 14/100\n",
      "451/450 [==============================] - 15s 34ms/step - loss: 0.3613 - accuracy: 0.8896 - val_loss: 0.3291 - val_accuracy: 0.9097\n",
      "Epoch 15/100\n",
      "451/450 [==============================] - 15s 34ms/step - loss: 0.3396 - accuracy: 0.8971 - val_loss: 0.3712 - val_accuracy: 0.9002\n",
      "Epoch 16/100\n",
      "451/450 [==============================] - 15s 33ms/step - loss: 0.3379 - accuracy: 0.9005 - val_loss: 0.2741 - val_accuracy: 0.9301\n",
      "Epoch 17/100\n",
      "451/450 [==============================] - 16s 35ms/step - loss: 0.3117 - accuracy: 0.9033 - val_loss: 0.2852 - val_accuracy: 0.9297\n",
      "Epoch 18/100\n",
      "451/450 [==============================] - 16s 34ms/step - loss: 0.2767 - accuracy: 0.9186 - val_loss: 0.2836 - val_accuracy: 0.9250\n",
      "Epoch 19/100\n",
      "451/450 [==============================] - 15s 34ms/step - loss: 0.2628 - accuracy: 0.9198 - val_loss: 0.2569 - val_accuracy: 0.9281\n",
      "Epoch 20/100\n",
      "451/450 [==============================] - 17s 38ms/step - loss: 0.2747 - accuracy: 0.9194 - val_loss: 0.2451 - val_accuracy: 0.9344\n",
      "Epoch 21/100\n",
      "451/450 [==============================] - 16s 36ms/step - loss: 0.2514 - accuracy: 0.9245 - val_loss: 0.2183 - val_accuracy: 0.9434\n",
      "Epoch 22/100\n",
      "451/450 [==============================] - 16s 34ms/step - loss: 0.2323 - accuracy: 0.9298 - val_loss: 0.2272 - val_accuracy: 0.9427\n",
      "Epoch 23/100\n",
      "451/450 [==============================] - 15s 34ms/step - loss: 0.2371 - accuracy: 0.9302 - val_loss: 0.2045 - val_accuracy: 0.9450\n",
      "Epoch 24/100\n",
      "451/450 [==============================] - 15s 34ms/step - loss: 0.2272 - accuracy: 0.9330 - val_loss: 0.2106 - val_accuracy: 0.9446\n",
      "Epoch 25/100\n",
      "451/450 [==============================] - 15s 32ms/step - loss: 0.2106 - accuracy: 0.9366 - val_loss: 0.2697 - val_accuracy: 0.9360\n",
      "Epoch 26/100\n",
      "451/450 [==============================] - 15s 33ms/step - loss: 0.2206 - accuracy: 0.9348 - val_loss: 0.2029 - val_accuracy: 0.9466\n",
      "Epoch 27/100\n",
      "451/450 [==============================] - 15s 33ms/step - loss: 0.2196 - accuracy: 0.9370 - val_loss: 0.2194 - val_accuracy: 0.9407\n",
      "Epoch 28/100\n",
      "451/450 [==============================] - 15s 33ms/step - loss: 0.2110 - accuracy: 0.9393 - val_loss: 0.2185 - val_accuracy: 0.9478\n",
      "Epoch 29/100\n",
      "451/450 [==============================] - 15s 33ms/step - loss: 0.1882 - accuracy: 0.9411 - val_loss: 0.2261 - val_accuracy: 0.9427\n",
      "Epoch 30/100\n",
      "451/450 [==============================] - 15s 33ms/step - loss: 0.1902 - accuracy: 0.9432 - val_loss: 0.2058 - val_accuracy: 0.9521\n",
      "Epoch 31/100\n",
      "451/450 [==============================] - 15s 33ms/step - loss: 0.1973 - accuracy: 0.9429 - val_loss: 0.2074 - val_accuracy: 0.9540\n",
      "Epoch 32/100\n",
      "451/450 [==============================] - 14s 31ms/step - loss: 0.1823 - accuracy: 0.9466 - val_loss: 0.1795 - val_accuracy: 0.9544\n",
      "Epoch 33/100\n",
      "451/450 [==============================] - 14s 32ms/step - loss: 0.1812 - accuracy: 0.9475 - val_loss: 0.2211 - val_accuracy: 0.9517\n",
      "Epoch 34/100\n",
      "451/450 [==============================] - 15s 33ms/step - loss: 0.1753 - accuracy: 0.9489 - val_loss: 0.1949 - val_accuracy: 0.9540\n",
      "Epoch 35/100\n",
      "451/450 [==============================] - 15s 32ms/step - loss: 0.1773 - accuracy: 0.9452 - val_loss: 0.1732 - val_accuracy: 0.9576\n",
      "Epoch 36/100\n",
      "451/450 [==============================] - 15s 33ms/step - loss: 0.1761 - accuracy: 0.9486 - val_loss: 0.1678 - val_accuracy: 0.9592\n",
      "Epoch 37/100\n",
      "105/450 [=====>........................] - ETA: 9s - loss: 0.1705 - accuracy: 0.9497 "
     ]
    }
   ],
   "source": [
    "## Inicio del entrenamiento\n",
    "epochs_num = 100\n",
    "model, opt = create_model_six_conv(X_train.shape[1:])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model, history = training(model, X_train, X_test, y_train, y_test, data_augmentation=True, epochs=epochs_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EU8mWUfRlUw-"
   },
   "outputs": [],
   "source": [
    "#Se guarda el modelo y el \"history\" que ayuda después para documentación\n",
    "pd.DataFrame.from_dict(history.history).to_csv('history.csv',index=False)\n",
    "model.save('New.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "UIEZ2MZtqzBk",
    "outputId": "c2243444-d293-40ec-8968-837f7ae81e62"
   },
   "outputs": [],
   "source": [
    "#Lee el csv creado\n",
    "data = pd.read_csv(\"history.csv\")\n",
    "\n",
    "#Se imprime la mejora de la red por epoca\n",
    "epochs= range(epochs_num)\n",
    "f, ax = plt.subplots(ncols=2, figsize=(15,6))\n",
    "ax[0].plot(epochs, data['loss'], label='loss')\n",
    "ax[0].plot(epochs, data['val_loss'], label='val_loss')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend()\n",
    "ax[1].plot(epochs, data['accuracy'], label='accuracy')\n",
    "ax[1].plot(epochs, data['val_accuracy'], label='val_accuracy')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "id": "QOmamEmAHmyA",
    "outputId": "c5061e0c-3fd9-4ee8-8afd-ca0081c8d60d"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions_last_epoch = model.predict(X_test, batch_size=32, verbose=1)\n",
    "\n",
    "Pred_y = np.argmax(predictions_last_epoch, axis=1)\n",
    "True_y = np.argmax(y_test, axis=1)\n",
    "target_names = list(map_characters.values())\n",
    "\n",
    "\n",
    "report = classification_report(True_y, Pred_y, target_names=target_names)\n",
    "print('\\n')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "b7rNBnLNO1Xc",
    "outputId": "cfaef194-e527-4ac0-b856-d4a565a71386"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "cnf_matrix = sklearn.metrics.confusion_matrix(np.where(y_test > 0)[1], np.argmax(predictions_last_epoch, axis=1))\n",
    "classes = list(map_characters.values())\n",
    "plt.imshow(cnf_matrix, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "_ = plt.xticks(tick_marks, classes, rotation=90)\n",
    "_ = plt.yticks(tick_marks, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "frfhX2R8q4SF",
    "outputId": "a24105b9-836c-4e1f-ed7e-06a930192f94"
   },
   "outputs": [],
   "source": [
    "#Se carga el mejor modelo y se imprime el loss y acc con el set de test\n",
    "#Crea un nuevo modelo y se le colocan los pesos guardados por el callback\n",
    "#Este proceso se puede hacer tambien con la funcion load_model_from_checkpoint\n",
    "\n",
    "input_shape=(64,64,3)\n",
    "Best_model, opt = create_model_six_conv(input_shape)\n",
    "Best_model.load_weights('best_weights.hdf5')\n",
    "Best_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "results = Best_model.evaluate(X_test, y_test, batch_size=128)\n",
    "print(\" \")\n",
    "print(\"Mejores resultados de entrenamiento\")\n",
    "print('Resultados de función de perdida, Porcentaje de exactitud:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "2vQ0Uovgx7JZ",
    "outputId": "607c9c5c-3f1f-4765-8b25-380cbecdf7a2"
   },
   "outputs": [],
   "source": [
    "#Se usa el modelo final y se imprime el loss y acc con el set de test\n",
    "#Esto para comparar los resultados del modelo final y el mejor modelo\n",
    "\n",
    "new_model = keras.models.load_model('New.h5')\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "results = new_model.evaluate(X_test, y_test, batch_size=128)\n",
    "print(\" \")\n",
    "print(\"Los últimos resultados de entrenamiento\")\n",
    "print('Resultados de función de perdida, Porcentaje de exactitud:', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitectura de la red neuronal entrenada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "colab_type": "code",
    "id": "AxsPLncjNLVJ",
    "outputId": "aa586c59-3de0-4f5f-bc72-19f938d00233"
   },
   "outputs": [],
   "source": [
    "#Explicación de como cargar directamente el modelo final guardado manualmente \n",
    "new_model = keras.models.load_model('New.h5')\n",
    "\n",
    "#Summary nos dice la arquitectura de la red neuronal\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AedsH1jjymHD"
   },
   "source": [
    "## Predicciones Manuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "juEUT5MyrnUd"
   },
   "outputs": [],
   "source": [
    "def plot_and_predict(image, model, BGR=False, pic_size=64 ,all_perc=False):\n",
    "    pics = []\n",
    "    img = io.imread(image)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    #Lectura de la imagen con OpenCV\n",
    "    a = cv2.imread(image)\n",
    "\n",
    "    #Esto es importante, si se entreno en blanco y negro se debe hacer la lectura\n",
    "    #en blanco y negro, por defecto esta en blanco y negro BGR = False\n",
    "    if BGR:\n",
    "        a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #Se hace el resize a pic_size x pic_size por defecto esto es 64x64 \n",
    "    a = cv2.resize(a, (pic_size,pic_size))    \n",
    "\n",
    "    #Se le da el formato adecuado\n",
    "    #Primero se convierte en lista\n",
    "    #Para que tenga forma (1,pic_size,pic_size,3) que es el shape que \n",
    "    #requiere la red, por defecto esto es (1,64,64,3)\n",
    "    pics.append(a)\n",
    "\n",
    "    #Luego se pasa a un numpy array que es el formato requerido\n",
    "    pics_format = np.array(pics)\n",
    "\n",
    "    #Finalmente se normaliza cada banda en numeros con punto flotantes entre 0 y 1\n",
    "    pics_format = pics_format.astype('float32') / 255\n",
    "\n",
    "    Prediction = model.predict(pics_format[[0]])\n",
    "    return Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "ZPUAUQGJsNvs",
    "outputId": "c9e8b172-5bbc-45e1-f9b0-549765839b4e"
   },
   "outputs": [],
   "source": [
    "name  = 'pic_0016.jpg'\n",
    "image = 'Images_Simpsons/Extra_Images/'\n",
    "image = 'characters/maggie_simpson/'\n",
    "\n",
    "new_model = keras.models.load_model('New.h5')\n",
    "predictions = plot_and_predict(image + name, new_model, pic_size=64)\n",
    "print(map_characters[np.argmax(predictions[0])].replace('_',' '))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
